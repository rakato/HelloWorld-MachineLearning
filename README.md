# HelloWorld-MachineLearning

## Repository for beginning steps in machine learning in R and Python

* Linear Regression
  - Housing Data Set in R

* Time Series Forecasting
  - ARIMA in r
  - ARIMA in Python
  
* Logisitic Regression:

  - <a href = "https://github.com/rakato/HelloWorld-MachineLearning/blob/master/pima_glm.r" > Pima Data Set in R </a>
   - <a href = "https://github.com/rakato/HelloWorld-MachineLearning/blob/master/pima_logistic.py" > Pima Data Set in Python </a>

* Multiple Models on Pima Dataset  
  
   - <a href ="https://topepo.github.io/caret/pre-processing.html#pp" > Pre-Processing with Caret Library </a>
   - <a href = "https://github.com/rakato/HelloWorld-MachineLearning/blob/master/multiple_models_pima.r" > CART, LDA, SVM, kNN, Random Forest in R </a>
   - <a href = "https://github.com/topepo/caret/tree/master/models/files" > List of Caret Models and Code in R </a>
   - <a href ="http://scikit-learn.org/stable/index.html" > Scikit-Learn Index </a>
 * Boosting
   - <a href ="https://www.cs.rit.edu/~rlaz/prec20092/slides/Bagging_and_Boosting.pdf" > RIT Bagging and Boosting pdf </a>
   - <a href ="https://en.wikipedia.org/wiki/AdaBoost"> Ada Boost Wikipedia </a>
   - <a href ="https://www.quora.com/What-is-an-intuitive-explanation-of-Gradient-Boosting"> Quora Intuative Gradient Boosting
   - <a href ="https://arxiv.org/pdf/1603.02754v1.pdf"> XGBoost: A Scalable Tree Boosting System</a>
   - <a href = "https://shankarmsy.github.io/stories/gbrt-sklearn.html" > Cal Housing Prices Boosting Trees for Regression Example </a>
   - <a href = "https://xgboost.readthedocs.io/en/latest/parameter.html"> Boosting Parameters <a/>
   - <a href = "https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf"> U of W:  Intro to Boosting <a/>

* XGBoost
   - <a href ="https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/" > Avoid Overfitting By Early Stopping </a>
   - <a href = "https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/"> Tune Learning Rate <a/>
   - <a href = "https://github.com/dmlc/xgboost/tree/master/demo#usecases"> Awesome XGBoost <a/>
   - <a href = "https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db"> Catboost vs. Light GBM vs. XGBoost <a/>
  
* Clustering

  - <a href = "https://github.com/rakato/HelloWorld-MachineLearning/blob/master/kmeansmtcars.r"> K-Means Mtcars Data Set in R </a>
 Â 
  - <a href = "https://en.wikipedia.org/wiki/K-means_clustering"> K-means Wikipedia Link </a>


* Deep-Learning
  
  - <a href = "http://yann.lecun.com/exdb/mnist/"> LeCun MINST Link </a>

  - <a href = "https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py">  Keras MINST FChollet example in Python  </a>

  - <a href = "https://github.com/rakato/HelloWorld-MachineLearning/blob/master/MNISTMultiLayer_perceptron.py"> Multi-Layer Perceptron in Python </a>

  - <a href = "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"> Cats and Dogs Image Recognition on very little data- Chollet example </a>
  
  
* Optimization  

  - <a href = "http://sebastianruder.com/optimizing-gradient-descent/" > Gradient Descent Overview </a>
  
  - <a href = "https://www.cs.toronto.edu/~urtasun/courses/CSC2515/tutorial_optimization.pdf" > Optimization for Machine Learning</a>
  
